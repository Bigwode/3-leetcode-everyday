### YOLO 9000

YOLO9000是在YOLO v2的基础上，采用了一种联合训练的方法，使得模型可以检测9000个类别。

首先在训练集的构建方面：按照各个类别之间的从属关系建立一种树型结构WordTree，将COCO数据集和ImageNet数据集结合起来作为训练集，考虑到COCO数据集相对于ImageNet数据量太少了，为了平衡两个数据集，对COCO做了过采样，使得两个数据集数据量比例接近1:4。

对于物体的标签，采用one-hot编码的形式，数据集中的每个物体的类别标签被组织成1个长度为9418的向量，向量中除在WordTree中从该物体对应的名词到根节点的路径上出现的词对应的类别标号处为1，其余位置为0。

在训练的过程中，当网络遇到来自检测数据集的图片时，用完整的YOLOv2loss进行反向传播计算，当网络遇到来自分类数据集的图片时，只用分类部分的loss进行反向传播。

在类别概率预测上使用层次softmax处理。

### 深度学习模型压缩方法

**前端压缩：**

1. **知识蒸馏**：知识蒸馏是让复杂模型学习到的**知识迁移**到小模型当中,使其保持其快速的计算速度前提下，同时拥有复杂模型的性能，达到模型压缩的目的。但与剪枝、量化等方法想比，效果较差。

2. **紧凑的模型结构设计**：主要是对神经网络卷积的方式进行改进，比如使用两个3x3的**卷积替换**一个5x5的卷积、使用**深度可分离卷积**等等方式降低计算参数量。

3. **滤波器层面的剪枝**：主要是对较小的权重矩阵整个剔除，然后对整个神经网络进行微调。

   ​

   **后端压缩：**


1. **低秩近似**：对于复杂网络，权重矩阵往往非常大，非常消耗存储和计算资源。低秩近似就是用若干个低秩矩阵组合重构大的权重矩阵，以此降低存储和计算资源消耗。
2. **未加限制的剪枝**：非结构化剪枝和结构化剪枝。非结构化剪枝是对神经网络中权重较小的权重或者权重矩阵进**剔除**，然后对整个神经网络进行微调；结构化剪枝是在网络优化目标中加入**权重稀疏正则项**，使部分权重在训练时趋于0。
3. **参数量化**：神经网络的参数类型一般是32位浮点型，使用**较小的精度**代替32位所表示的精度。或者是将多个权重映射到同一数值，权重共享
4. **二指网络**：对于32bit浮点型数用1bit二进制数-1或者1表示。

<https://blog.csdn.net/wspba/article/details/75671573> 

https://blog.csdn.net/Touch_Dream/article/details/78441332

### 深度学习模型优化加速方法

（1）Op-level的快速算法：FFT Conv2d (7x7, 9x9), Winograd Conv2d (3x3, 5x5) 等；
（2）Layer-level的快速算法：Sparse-block net 等；
（3）优化工具与库：TensorRT (Nvidia), Tensor Comprehension (Facebook) 和 Distiller (Intel) 等；

## Fast RCNN

创新点：

1. 只对整幅图像进行一次特征提取，避免R-CNN中的冗余特征提取
2. 用RoI pooling层替换最后一层的max pooling层，同时引入建议框数据，提取相应建议框特征
3. Fast R-CNN网络末尾采用并行的不同的全连接层，可同时输出分类结果和窗口回归结果，实现了end-to-end的多任务训练【建议框提取除外】，也不需要额外的特征存储空间【R-CNN中的特征需要保持到本地，来供SVM和Bounding-box regression进行训练】
4. 采用SVD（奇异值分解）对Fast R-CNN网络末尾并行的全连接层进行分解，减少计算复杂度，加快检测速度。



